{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tri334/Naive_Hoax_Covid/blob/master/filter_hoax_naive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSab26RrugvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2c589ba0-7fe0-4dac-9b3d-cf2b8abf7b33"
      },
      "source": [
        "!git clone https://github.com/Tri334/Naive_Hoax_Covid.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Naive_Hoax_Covid'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/29)\u001b[K\rremote: Counting objects:   6% (2/29)\u001b[K\rremote: Counting objects:  10% (3/29)\u001b[K\rremote: Counting objects:  13% (4/29)\u001b[K\rremote: Counting objects:  17% (5/29)\u001b[K\rremote: Counting objects:  20% (6/29)\u001b[K\rremote: Counting objects:  24% (7/29)\u001b[K\rremote: Counting objects:  27% (8/29)\u001b[K\rremote: Counting objects:  31% (9/29)\u001b[K\rremote: Counting objects:  34% (10/29)\u001b[K\rremote: Counting objects:  37% (11/29)\u001b[K\rremote: Counting objects:  41% (12/29)\u001b[K\rremote: Counting objects:  44% (13/29)\u001b[K\rremote: Counting objects:  48% (14/29)\u001b[K\rremote: Counting objects:  51% (15/29)\u001b[K\rremote: Counting objects:  55% (16/29)\u001b[K\rremote: Counting objects:  58% (17/29)\u001b[K\rremote: Counting objects:  62% (18/29)\u001b[K\rremote: Counting objects:  65% (19/29)\u001b[K\rremote: Counting objects:  68% (20/29)\u001b[K\rremote: Counting objects:  72% (21/29)\u001b[K\rremote: Counting objects:  75% (22/29)\u001b[K\rremote: Counting objects:  79% (23/29)\u001b[K\rremote: Counting objects:  82% (24/29)\u001b[K\rremote: Counting objects:  86% (25/29)\u001b[K\rremote: Counting objects:  89% (26/29)\u001b[K\rremote: Counting objects:  93% (27/29)\u001b[K\rremote: Counting objects:  96% (28/29)\u001b[K\rremote: Counting objects: 100% (29/29)\u001b[K\rremote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects:   5% (1/20)\u001b[K\rremote: Compressing objects:  10% (2/20)\u001b[K\rremote: Compressing objects:  15% (3/20)\u001b[K\rremote: Compressing objects:  20% (4/20)\u001b[K\rremote: Compressing objects:  25% (5/20)\u001b[K\rremote: Compressing objects:  30% (6/20)\u001b[K\rremote: Compressing objects:  35% (7/20)\u001b[K\rremote: Compressing objects:  40% (8/20)\u001b[K\rremote: Compressing objects:  45% (9/20)\u001b[K\rremote: Compressing objects:  50% (10/20)\u001b[K\rremote: Compressing objects:  55% (11/20)\u001b[K\rremote: Compressing objects:  60% (12/20)\u001b[K\rremote: Compressing objects:  65% (13/20)\u001b[K\rremote: Compressing objects:  70% (14/20)\u001b[K\rremote: Compressing objects:  75% (15/20)\u001b[K\rremote: Compressing objects:  80% (16/20)\u001b[K\rremote: Compressing objects:  85% (17/20)\u001b[K\rremote: Compressing objects:  90% (18/20)\u001b[K\rremote: Compressing objects:  95% (19/20)\u001b[K\rremote: Compressing objects: 100% (20/20)\u001b[K\rremote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "Unpacking objects:   3% (1/29)   \rUnpacking objects:   6% (2/29)   \rUnpacking objects:  10% (3/29)   \rUnpacking objects:  13% (4/29)   \rUnpacking objects:  17% (5/29)   \rUnpacking objects:  20% (6/29)   \rUnpacking objects:  24% (7/29)   \rUnpacking objects:  27% (8/29)   \rUnpacking objects:  31% (9/29)   \rUnpacking objects:  34% (10/29)   \rUnpacking objects:  37% (11/29)   \rUnpacking objects:  41% (12/29)   \rUnpacking objects:  44% (13/29)   \rUnpacking objects:  48% (14/29)   \rUnpacking objects:  51% (15/29)   \rUnpacking objects:  55% (16/29)   \rUnpacking objects:  58% (17/29)   \rUnpacking objects:  62% (18/29)   \rremote: Total 29 (delta 9), reused 23 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects:  65% (19/29)   \rUnpacking objects:  68% (20/29)   \rUnpacking objects:  72% (21/29)   \rUnpacking objects:  75% (22/29)   \rUnpacking objects:  79% (23/29)   \rUnpacking objects:  82% (24/29)   \rUnpacking objects:  86% (25/29)   \rUnpacking objects:  89% (26/29)   \rUnpacking objects:  93% (27/29)   \rUnpacking objects:  96% (28/29)   \rUnpacking objects: 100% (29/29)   \rUnpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1UYVc_VmX7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "fcb8b5ed-f0bb-43d9-af0d-d7668b1bac3e"
      },
      "source": [
        "pip install Sastrawi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbczwkqvlJOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup as sp\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import base64\n",
        "import requests\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "\n",
        "\n",
        "with open(\"/content/Naive_Hoax_Covid/stopword2016.txt\",\"r\") as stopword: stopword = stopword.read().splitlines()\n",
        "\n",
        "\n",
        "def openFile(corpus):\n",
        "    file = open(corpus, encoding=\"utf8\")\n",
        "    soup = sp(file,'html.parser')\n",
        "    doc_berita = soup.find_all(\"doc\")\n",
        "    return doc_berita\n",
        "\n",
        "def priorProbability(berita):\n",
        "    categori_only = {}\n",
        "    prior_proba ={}\n",
        "    jumlah = 0\n",
        "    for item in berita:\n",
        "        cat = item.find('cat').text\n",
        "        cat = preprocessing(cat)\n",
        "        if cat:\n",
        "            if cat in categori_only:\n",
        "                categori_only[cat]+=1\n",
        "            else:\n",
        "                categori_only[cat]=1\n",
        "    for item in categori_only:\n",
        "        jumlah+=categori_only[item]\n",
        "    for items in categori_only:\n",
        "        prior_proba[items]=(categori_only[items]/jumlah)\n",
        "    return prior_proba\n",
        "\n",
        "def preprocessing(berita):\n",
        "    cleaning_words = re.sub(\"\\W+\",\" \", berita)\n",
        "    clean = cleaning_words.lower()\n",
        "\n",
        "    tokenize = re.findall(\"\\w+\", clean)\n",
        "    token = \" \".join(tokenize)\n",
        "    return stemmer.stem(token)\n",
        "\n",
        "def webCraw(berita):\n",
        "    list_berita = []\n",
        "    list_berita_cat = []\n",
        "    list_tidak_ada_cat = []\n",
        "    for item in berita:\n",
        "        berita = item.find(\"berita\").text\n",
        "        cat = item.find(\"cat\").text\n",
        "        if cat:\n",
        "            cat = preprocessing(cat)\n",
        "            berita = preprocessing(berita)\n",
        "            list_berita.append(berita)\n",
        "            list_berita_cat.append([berita] + [cat])\n",
        "        else:\n",
        "            list_tidak_ada_cat.append(berita)\n",
        "    with open(\"list_berita.json\", \"w\") as write_file:\n",
        "        json.dump(list_berita, write_file)\n",
        "\n",
        "    with open(\"list_berita_cat.json\", \"w\") as write_file:\n",
        "        json.dump(list_berita_cat, write_file)\n",
        "\n",
        "    with open(\"list_tidak_ada_cat.json\", \"w\") as write_file:\n",
        "        json.dump(list_tidak_ada_cat, write_file)\n",
        "\n",
        "def termUnik(list_berita,stopword):\n",
        "    unique = []\n",
        "    kata = \" \".join(list_berita)\n",
        "    token = kata.split(' ')\n",
        "    for item in token:\n",
        "        if item:\n",
        "            if item not in stopword:\n",
        "                if item not in unique:\n",
        "                    unique.append(item)\n",
        "    unique.sort()\n",
        "    return unique\n",
        "\n",
        "def dikategorikan(berita_cat):\n",
        "    categorized = {}\n",
        "    for item in berita_cat:\n",
        "        if item[0] or item[1]:\n",
        "            if item[1] in categorized:\n",
        "                old = categorized[item[1]]\n",
        "                categorized.update({item[1]:old +\" \"+item[0]})\n",
        "            else:\n",
        "                categorized[item[1]] = item[0]\n",
        "\n",
        "    for key in categorized:\n",
        "        tokenize = categorized[key].split(' ')\n",
        "        categorized[key]= tokenize\n",
        "\n",
        "    return categorized\n",
        "\n",
        "def termWeight(categori,kata_unik):\n",
        "    weight_cat_dict ={}\n",
        "    for key in categori:\n",
        "        # print(key)\n",
        "        waight_temp = []\n",
        "        tes = {}\n",
        "        for i in range(len(kata_unik)):\n",
        "            score = 0\n",
        "            for item in categori[key]:\n",
        "                if kata_unik[i] == item:\n",
        "                    score += 1\n",
        "            tes[kata_unik[i]] = score\n",
        "            waight_temp.append(score)\n",
        "        weight_cat_dict[key] = tes\n",
        "    return weight_cat_dict\n",
        "\n",
        "def conProba(weight_cat_dict,term_unik):\n",
        "    sum_weight = {}\n",
        "    possible = {}\n",
        "    for item in weight_cat_dict:\n",
        "        term_count = 0\n",
        "        for val in weight_cat_dict[item]:\n",
        "            term_count+=weight_cat_dict[item][val]\n",
        "        sum_weight[item]= term_count\n",
        "\n",
        "    for key in weight_cat_dict:\n",
        "        poss_term=0\n",
        "        temp = {}\n",
        "        for value in weight_cat_dict[key]:\n",
        "            poss_term = weight_cat_dict[key][value]\n",
        "            p_kata = (poss_term+1)/(sum_weight[key]+ len(term_unik))\n",
        "            temp[value]=p_kata\n",
        "        possible[key]=temp\n",
        "    return possible\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOzSQdeKqPQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "59e4d218-6615-41f1-b1db-de61c4bb86f9"
      },
      "source": [
        "list_berita = 'https://raw.githubusercontent.com/Tri334/Naive_Hoax_Covid/master/list_berita.json'\n",
        "list_berita_cat = 'https://raw.githubusercontent.com/Tri334/Naive_Hoax_Covid/master/list_berita_cat.json'\n",
        "\n",
        "list_berita = requests.get(list_berita)\n",
        "list_berita = json.loads(list_berita)\n",
        "\n",
        "list_berita_cat = requests.get(list_berita_cat)\n",
        "list_berita_cat = list_berita_cat.json\n",
        "\n",
        "print(list_berita[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-81f792350455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlist_berita\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_berita\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlist_berita\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_berita\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlist_berita_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_berita_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             raise TypeError('the JSON object must be str, bytes or bytearray, '\n\u001b[0;32m--> 348\u001b[0;31m                             'not {!r}'.format(s.__class__.__name__))\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogatepass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not 'Response'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq2v6cehsMll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mencari kata unik dengan menghilangkan stopword\n",
        "term_unik = termUnik(list_berita,stopword)\n",
        "print(f\"banyak: {len(term_unik)}\\n\"\n",
        "      f\"Term_unik: {term_unik}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-bbr20SsuFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mengkategorikan berdasarkan kategori\n",
        "dikategori = dikategorikan(list_berita_cat)\n",
        "# print(f\"Berdasar Kategori:\\n{dikategori}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kwy1PlGsw7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menghitung Raw TF berdasarkan kata unik\n",
        "term_weight_dict = termWeight(dikategori,term_unik)\n",
        "# print(f\"Bobot masing-masing kata RAW:\\n{term_weight_dict}\\n\")\n",
        "print(pd.DataFrame(term_weight_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a9_Vy4psxvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Menghitung P(w|xi) setiap kategori\n",
        "condisional_probability = conProba(term_weight_dict,term_unik)\n",
        "print(f\"\\nPosterior:\\n{pd.DataFrame(condisional_probability)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}